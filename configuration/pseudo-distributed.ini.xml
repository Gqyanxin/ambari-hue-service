<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration>

  <property>
    <name>content</name>
    <description>Hue Configure File</description>
    <value>
#####################################
# DEVELOPMENT EDITION
#####################################

# Hue configuration file
# ===================================
#
# For complete documentation about the contents of this file, run
#   $ (hue_root)/build/env/bin/hue config_help
#
# All .ini files under the current directory are treated equally.  Their
# contents are merged to form the Hue configuration, which can
# can be viewed on the Hue at
#   http://(hue_host):(port)/dump_config

###########################################################################
# General configuration for core Desktop features (authentication, etc)
###########################################################################

[desktop]

  # Set this to a random string, the longer the better.
  # This is used for secure hashing in the session store.
  secret_key={{desktop_secret_key}}

  # Execute this script to produce the Django secret key. This will be used when
  # 'secret_key' is not set.
  {% if desktop_secret_key.strip() == '' %}
  secret_key_script={{desktop_secret_key_script}}
  {% else %}
  # secret_key_script=
  {% endif %}

  # Webserver listens on this address and port
  http_host=0.0.0.0
  http_port={{http_port}}

  # TODO Add hue_load_balancer
  # A comma-separated list of available Hue load balancers
  ## hue_load_balancer=

  # Time zone name
  time_zone={{desktop_time_zone}}

  # Enable or disable Django debug mode.
  django_debug_mode={{desktop_django_debug_mode}}

  # TODO Add dev
  # Enable development mode, where notably static files are not cached.
  dev=true

  # Enable or disable database debug mode.
  database_logging={{desktop_database_logging}}

  # Whether to send debug messages from JavaScript to the server logs.
  send_dbug_messages={{desktop_send_dbug_messages}}

  # Enable or disable backtrace for server error
  http_500_debug_mode={{desktop_http_500_debug_mode}}

  # IS DO Add instrumentation
  # Enable or disable instrumentation. If django_debug_mode is True, this is automatically enabled
  {% if desktop_django_debug_mode == 'true' %}
  instrumentation=true
  {% else %}
  ## instrumentation=false
  {% endif %}

  # TODO Del memory_profiler
  # Enable or disable memory profiling.
  # memory_profiler={{desktop_memory_profiler}}

  # Server email for internal error messages
  django_server_email={{desktop_django_server_email}}

  # Email backend
  django_email_backend={{desktop_django_email_backend}}

  # TODO Add use_cherrypy_server
  # Set to true to use CherryPy as the webserver, set to false
  # to use Gunicorn as the webserver. Defaults to CherryPy if
  # key is not specified.
  ## use_cherrypy_server=true

  # TODO Add gunicorn_work_class
  # Gunicorn work class: gevent or evenlet, gthread or sync.
  ## gunicorn_work_class=eventlet

  # TODO Add gunicorn_number_of_workers
  # The number of Gunicorn worker processes. If not specified, it uses: (number of CPU * 2) + 1.
  ## gunicorn_number_of_workers=1

  # Webserver runs as this user
  server_user={{desktop_server_user}}
  server_group={{desktop_server_group}}

  # This should be the Hue admin and proxy user
  default_user={{desktop_default_user}}

  # This should be the hadoop cluster admin
  default_hdfs_superuser={{desktop_default_hdfs_superuser}}

  # If set to false, runcpserver will not actually start the web server.
  # Used if Apache is being used as a WSGI container.
  enable_server={{desktop_enable_server}}

  # Number of threads used by the CherryPy web server
  cherrypy_server_threads={{desktop_cherrypy_server_threads}}

  # TODO Add sasl_max_buffer
  # This property specifies the maximum size of the receive buffer in bytes in thrift sasl communication,
  # default value is 2097152 (2 MB), which equals to (2 * 1024 * 1024)
  ## sasl_max_buffer=2097152

  # TODO Add enable_smart_thrift_pool
  # Hue will try to get the actual host of the Service, even if it resides behind a load balancer.
  # This will enable an automatic configuration of the service without requiring custom configuration of the service load balancer.
  # This is available for the Impala service only currently. It is highly recommended to only point to a series of coordinator-only nodes only.
  # enable_smart_thrift_pool=false

 {% if desktop_ssl_enable %}
  # Filename of SSL Certificate
  ssl_certificate={{desktop_ssl_certificate}}
  ssl_private_key={{desktop_ssl_private_key}}
  ssl_certificate_chain={{desktop_ssl_certificate_chain}}
  ssl_password={{desktop_ssl_password}}
  {% if ssl_password.strip() == '' %}
  ssl_password_script={{desktop_ssl_password_script}}
  {% else %}
  ## ssl_password_script=
  {% endif %}
  secure_content_type_nosniff={{desktop_secure_content_type_nosniff}}
  secure_browser_xss_filter={{desktop_secure_browser_xss_filter}}
  secure_content_security_policy={{desktop_secure_content_security_policy}}
  secure_ssl_redirect={{desktop_secure_ssl_redirect}}
  secure_redirect_host={{desktop_secure_redirect_host}}
  secure_redirect_exempt={{desktop_secure_redirect_exempt}}
  secure_hsts_seconds={{desktop_secure_hsts_seconds}}
  secure_hsts_include_subdomains={{desktop_secure_hsts_include_subdomains}}
  ssl_cipher_list={{desktop_ssl_cipher_list}}
  ssl_cacerts={{desktop_ssl_cacerts}}
 {% else %}
  # Filename of SSL Certificate
  ## ssl_certificate=

  # Filename of SSL RSA Private Key
  ## ssl_private_key=

  # Filename of SSL Certificate Chain
  ## ssl_certificate_chain=

  # SSL certificate password
  ## ssl_password=

  # Execute this script to produce the SSL password. This will be used when `ssl_password` is not set.
  ## ssl_password_script=

  # TODO Add ssl_no_renegotiation
  # Disable all renegotiation in TLSv1.2 and earlier. Do not send HelloRequest messages, and ignore renegotiation requests via ClientHello.
  # This option is only available with OpenSSL 1.1.0h and later and python 3.7
  ## ssl_no_renegotiation=python.version >= 3.7

  # X-Content-Type-Options: nosniff This is a HTTP response header feature that helps prevent attacks based on MIME-type confusion.
  ## secure_content_type_nosniff=true

  # X-Xss-Protection: \"1; mode=block\" This is a HTTP response header feature to force XSS protection.
  ## secure_browser_xss_filter=true

  # X-Content-Type-Options: nosniff This is a HTTP response header feature that helps prevent attacks based on MIME-type confusion.
  ## secure_content_security_policy="script-src 'self' 'unsafe-inline' 'unsafe-eval' *.google-analytics.com *.doubleclick.net *.mathjax.org data:;img-src 'self' *.google-analytics.com *.doubleclick.net *.tile.osm.org data:;style-src 'self' 'unsafe-inline';connect-src 'self';child-src 'self' data:;object-src 'none'"

  # Strict-Transport-Security HTTP Strict Transport Security(HSTS) is a policy which is communicated by the server to the user agent via HTTP response header
  ## field name “Strict-Transport-Security”. HSTS policy specifies a period of time during which the user agent(browser) should only access the server in a secure fashion(https).
  ## secure_ssl_redirect=False
  ## secure_redirect_host=0.0.0.0
  ## secure_redirect_exempt=[]
  ## secure_hsts_seconds=31536000
  ## secure_hsts_include_subdomains=true

  # List of allowed and disallowed ciphers in cipher list format.
  # See http://www.openssl.org/docs/apps/ciphers.html for more information on
  # cipher list format. This list is from
  # https://wiki.mozilla.org/Security/Server_Side_TLS v3.7 intermediate
  # recommendation, which should be compatible with Firefox 1, Chrome 1, IE 7,
  # Opera 5 and Safari 1.

  ## ssl_cipher_list=ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA

  # Path to default Certificate Authority certificates.
  ## ssl_cacerts=/etc/hue/cacerts.pem
 {% endif %}

  # Choose whether Hue should validate certificates received from the server.
  # validate={{desktop_validate}}
  ssl_validate={{desktop_validate}}

  # Default LDAP/PAM/.. username and password of the hue user used for authentications with other services.
  # Inactive if password is empty.
  # e.g. LDAP pass-through authentication for HiveServer2 or Impala. Apps can override them individually.
  ## auth_username={{desktop_auth_username}}
  ## auth_password={{desktop_auth_password}}

  # Default encoding for site data
  default_site_encoding={{desktop_default_site_encoding}}

  # Help improve Hue with anonymous usage analytics.
  # Use Google Analytics to see how many times an application or specific section of an application is used, nothing more.
  ## collect_usage={{desktop_collect_usage}}

  # TODO Add gtag_id
  ## gtag_id='G-25K7599S1Q'

  # Tile layer server URL for the Leaflet map charts
  # Read more on http://leafletjs.com/reference.html#tilelayer
  # Make sure you add the tile domain to the img-src section of the 'secure_content_security_policy' configuration parameter as well.
  ## leaflet_tile_layer={{desktop_leaflet_tile_layer}}

  # The copyright message for the specified Leaflet maps Tile Layer
  ## leaflet_tile_layer_attribution={{desktop_leaflet_tile_layer_attribution}}

  # TODO Add leaflet_map_options
  # All the map options accordingly to http://leafletjs.com/reference-0.7.7.html#map-options
  # To change CRS, just use the name, ie. "EPSG4326"
  ## leaflet_map_options='{}'

  # TODO Add leaflet_tile_layer_options
  # All the tile layer options, accordingly to http://leafletjs.com/reference-0.7.7.html#tilelayer
  ## leaflet_tile_layer_options='{}'

  # X-Frame-Options HTTP header value. Use 'DENY' to deny framing completely                   
  http_x_frame_options={{desktop_http_x_frame_options}}

  # Enable X-Forwarded-Host header if the load balancer requires it.
  use_x_forwarded_host={{desktop_use_x_forwarded_host}}

  # Support for HTTPS termination at the load-balancer level with SECURE_PROXY_SSL_HEADER.
  secure_proxy_ssl_header={{desktop_secure_proxy_ssl_header}}

  # Comma-separated list of Django middleware classes to use.
  # See https://docs.djangoproject.com/en/1.4/ref/middleware/ for more details on middlewares in Django.
  ## middleware={{desktop_middleware}}

  # Comma-separated list of regular expressions, which match the redirect URL.
  # For example, to restrict to your local domain and FQDN, the following value can be used:
  # ^\/.*$,^http:\/\/www.mydomain.com\/.*$
  redirect_whitelist={{desktop_redirect_whitelist}}

  # Comma separated list of apps to not load at server startup.
  # e.g.: pig,zookeeper
  app_blacklist={{app_blacklist}}

  # TODO Add cluster_id
  # Id of the cluster where Hue is located.
  ## cluster_id='default'

  # Choose whether to show the new SQL editor.
  use_new_editor={{desktop_use_new_editor}}

  # TODO Add enable_download
  # Global setting to allow or disable end user downloads in all Hue.
  # e.g. Query result in Editors and Dashboards, file in File Browser...
  ## enable_download=true

  # TODO Add enable_sharing
  # Global setting to enable or disable document sharing.
  # Note that this does not affect currently shared documents.
  ## enable_sharing=true

  # TODO Add enable_sql_syntax_check
  # Choose whether to enable the new SQL syntax checker or not
  ## enable_sql_syntax_check=true

  # TODO Add use_new_charts
  # Choose whether to use new charting library across the whole Hue.
  ## use_new_charts=false

  # TODO Add enable_organizations
  # Choose whether to allow multi tenancy or not.
  ## enable_organizations=false

  # Editor autocomplete timeout (ms) when fetching columns, fields, tables etc.
  # To disable this type of autocompletion set the value to 0
  editor_autocomplete_timeout={{desktop_editor_autocomplete_timeout}}

  # Enable saved default configurations for Hive, Impala, Spark, and Oozie.
  use_default_configuration={{desktop_use_default_configuration}}

  # The directory where to store the auditing logs. Auditing is disable if the value is empty.
  # e.g. /var/log/hue/audit.log
  audit_event_log_dir={{desktop_audit_event_log_dir}}

  # Size in KB/MB/GB for audit log to rollover.
  audit_log_max_file_size={{desktop_audit_log_max_file_size}}

  # TODO Add rest_conn_timeout
  # Timeout in seconds for REST calls.
  ## rest_conn_timeout=120

  # A json file containing a list of log redaction rules for cleaning sensitive data
  # from log files. It is defined as:
  #
  # {
  #   "version": 1,
  #   "rules": [
  #     {
  #       "description": "This is the first rule",
  #       "trigger": "triggerstring 1",
  #       "search": "regex 1",
  #       "replace": "replace 1"
  #     },
  #     {
  #       "description": "This is the second rule",
  #       "trigger": "triggerstring 2",
  #       "search": "regex 2",
  #       "replace": "replace 2"
  #     }
  #   ]
  # }
  #
  # Redaction works by searching a string for the [TRIGGER] string. If found,
  # the [REGEX] is used to replace sensitive information with the
  # [REDACTION_MASK].  If specified with `log_redaction_string`, the
  # `log_redaction_string` rules will be executed after the
  # `log_redaction_file` rules.
  #
  # For example, here is a file that would redact passwords and social security numbers:

  # {
  #   "version": 1,
  #   "rules": [
  #     {
  #       "description": "Redact passwords",
  #       "trigger": "password",
  #       "search": "password=\".*\"",
  #       "replace": "password=\"XXX\""
  #     },
  #     {
  #       "description": "Redact social security numbers",
  #       "trigger": "",
  #       "search": "\d{3}-\d{2}-\d{4}",
  #       "replace": "XXX-XX-XXXX"
  #     }
  #   ]
  # }
  # log_redaction_file={{desktop_log_redaction_file}}

  # Comma separated list of strings representing the host/domain names that the Hue server can serve.
  # e.g.: localhost,domain1,*
  allowed_hosts={{desktop_allowed_hosts}}

  # TODO Add rest_response_size
  # Number of characters in rest api reponse calls to dump to the logs when debug is enabled. Set to -1 for entire response.
  ## rest_response_size=2000

  # TODO Add enable_prometheus
  # Turn on Prometheus metrics end point /metrics.
  ## enable_prometheus=false

  # TODO Add enable_gist
  # Turn on the Gist snippet sharing.
  ## enable_gist=true

  # TODO Add enable_gist_preview
  # Add public description so that the link can be unfurled in a preview by websites like Slack.
  # Only enabled automatically in private setups.
  ## enable_gist_preview=true

  # TODO Add enable_link_sharing
  # Turn on the direct link sharing of saved document.
  ## enable_link_sharing=true

  # TODO Add use_thrift_http_jwt
  # Use JWT as Bearer header for authentication when using Thrift over HTTP transport.
  ## use_thrift_http_jwt=false

  # TODO Add disable_local_storage
  # Hue uses Localstorage to keep the users settings and database preferences.
  # Please make this value true in case local storage should not be used
  # default value is false
  ## disable_local_storage = false

  # Administrators
  # ----------------
  [[django_admins]]
    ## [[[admin1]]]
    ## name=Hue
    ## email=hue@localhost.com

  # UI customizations
  # -------------------
  [[custom]]

    # Top banner HTML code
    # e.g. (H4)Test Lab A2 Hue Services(/H4)
<!--    ##  banner_top_html='<div style="padding: 4px; text-align: center; background-color: #003F6C; color: #DBE8F1">This is Hue 4 Beta! - Please feel free to email any feedback / questions to <a href="mailto:team@gethue.com" target="_blank" style="color: #FFF; font-weight: bold">team@gethue.com</a> or <a href="https://twitter.com/gethue" target="_blank" style="color: #FFF; font-weight: bold">@gethue</a>.</div>'-->
        #  banner_top_html=

    # Login splash HTML code
    # e.g. WARNING: You are required to have authorization before you proceed
<!--    ## login_splash_html=<h4>GetHue.com</h4><br/><br/>WARNING: You have accessed a computer managed by GetHue. You are required to have authorization from GetHue before you proceed.-->
    # login_splash_html=

    # Cache timeout in milliseconds for the assist, autocomplete, etc.
    # defaults to 86400000 (1 day), set to 0 to disable caching
    ## cacheable_ttl=86400000

    # TODO Add logo_svg
    # SVG code to replace the default Hue logo in the top bar and sign in screen
<!--    # e.g. <image xlink:href="/static/desktop/art/hue-logo-mini-white.png" x="0" y="0" height="40" width="160" />-->
    ## logo_svg=

  # Configuration options for user authentication into the web application
  # ------------------------------------------------------------------------
  [[auth]]

    # Authentication backend. Common settings are:
    # - desktop.auth.backend.AllowFirstUserDjangoBackend
    #     (Default. Fist login becomes and admin, then relies on user accounts)
    # - django.contrib.auth.backends.ModelBackend (entirely Django backend)
    # - desktop.auth.backend.AllowAllBackend (allows everyone)
    # - desktop.auth.backend.LdapBackend
    # - desktop.auth.backend.PamBackend
    # - desktop.auth.backend.SpnegoDjangoBackend
    # - desktop.auth.backend.KnoxSpnegoDjangoBackend
    # - desktop.auth.backend.RemoteUserDjangoBackend
    # - libsaml.backend.SAML2Backend
    # - desktop.auth.backend.OIDCBackend (New oauth, support Twitter, Facebook, Google+ and Linkedin)
    # Multiple Authentication backend combinations are supported by specifying a comma-separated list in order of priority.
    ## backend=desktop.auth.backend.AllowFirstUserDjangoBackend
    backend={{desktop_auth_backend}}

    # IS DO Add api_auth
    # Multiple Authentication backends for REST APIs are supported by specifying a comma-separated list in order of priority.
    api_auth={{desktop_auth_api_auth}}

    # Class which defines extra accessor methods for User objects.
    user_aug={{desktop_auth_user_aug}}

    # The service to use when querying PAM.
    pam_service={{desktop_auth_pam_service}}

    # TODO Add pam_use_pwd_module
    # To use Python unix pwd module to get the username from the entered credentials in Hue if Centrify like PAM service is in use.
    # This will set the username to what is being returned by the pwd module.
    ## pam_use_pwd_module=false

    # When using the desktop.auth.backend.RemoteUserDjangoBackend, this sets
    # the normalized name of the header that contains the remote user.
    # The HTTP header in the request is converted to a key by converting
    # all characters to uppercase, replacing any hyphens with underscores
    # and adding an HTTP_ prefix to the name. So, for example, if the header
    # is called Remote-User that would be configured as HTTP_REMOTE_USER
    #
    # Defaults to HTTP_REMOTE_USER
    remote_user_header={{desktop_auth_remote_user_header}}

    # Ignore the case of usernames when searching for existing users.
    # Supported in remoteUserDjangoBackend and SpnegoDjangoBackend
    ignore_username_case={{desktop_auth_ignore_username_case}}

    # Forcibly cast usernames to lowercase, takes precedence over force_username_uppercase
    # Supported in remoteUserDjangoBackend and SpnegoDjangoBackend
    force_username_lowercase={{desktop_auth_force_username_lowercase}}

	# Forcibly cast usernames to uppercase, cannot be combined with force_username_lowercase
    force_username_uppercase={{desktop_auth_force_username_uppercase}}

    # Users will expire after they have not logged in for 'n' amount of seconds.
    # A negative number means that users will never expire.
    expires_after={{desktop_auth_expires_after}}

    # Apply 'expires_after' to superusers.
    expire_superusers={{desktop_auth_expire_superusers}}

    # Users will automatically be logged out after 'n' seconds of inactivity.
    # A negative number means that idle sessions will not be timed out.
    idle_session_timeout={{desktop_auth_idle_session_timeout}}

    # Force users to change password on first login with desktop.auth.backend.AllowFirstUserDjangoBackend
    change_default_password={{desktop_auth_change_default_password}}

    # Number of login attempts allowed before a record is created for failed logins
    login_failure_limit={{desktop_auth_login_failure_limit}}

    # After number of allowed login attempts are exceeded, do we lock out this IP and optionally user agent?
    login_lock_out_at_failure={{desktop_auth_login_lock_out_at_failure}}

    # If set, defines period of inactivity in seconds after which failed logins will be forgotten
    login_cooloff_time={{desktop_auth_login_cooloff_time}}

    # If True, lock out based on an IP address AND a user agent.
	# This means requests from different user agents but from the same IP are treated differently.
    login_lock_out_use_user_agent={{desktop_auth_login_lock_out_use_user_agent}}

    # If True, lock out based on IP and user
    login_lock_out_by_combination_user_and_ip={{desktop_auth_login_lock_out_by_combination_user_and_ip}}

	# If True, it will look for the IP address from the header defined at reverse_proxy_header.
    behind_reverse_proxy={{desktop_auth_behind_reverse_proxy}}

    # If behind_reverse_proxy is True, it will look for the IP address from this header. Default: HTTP_X_FORWARDED_FOR
    reverse_proxy_header={{desktop_auth_reverse_proxy_header}}

    # TODO Add [[[jwt]]] module
    [[[jwt]]]
      # Adds custom JWT Authentication backend for REST APIs in top priority.
      ## is_enabled=false

      # Endpoint to fetch the public key from verification server.
      ## key_server_url=https://ext_authz:8000

      # The identifier of the service issued the JWT
      ## issuer=None

      # The identifier of the resource intend to access
      ## audience=None

      # Verify custom JWT signature.
      ## verify=true
	
  # Configuration options for connecting to LDAP and Active Directory
  # -------------------------------------------------------------------
  [[ldap]]
   {% if usersync_enabled and usersync_source == 'ldap' %}
    base_dn={{usersync_ldap_base_dn}}
    ldap_url={{usersync_ldap_url}}
    nt_domain={{usersync_ldap_nt_domain}}
    ldap_cert={{usersync_ldap_cert}}
    use_start_tls={{usersync_ldap_use_start_tls}}
    bind_dn={{usersync_ldap_bind_dn}}
    bind_password={{usersync_ldap_bind_password}}
    {% if usersync_ldap_bind_password.strip() == '' %}
    bind_password_script={{usersync_ldap_bind_password_script}}
    {% else %}
    ## bind_password_script=
    {% endif %}
    ldap_username_pattern={{usersync_ldap_username_pattern}}
    create_users_on_login = {{usersync_ldap_create_users_on_login}}
    sync_groups_on_login={{usersync_ldap_sync_groups_on_login}}
    # TODO Add login_groups
    login_groups=
    ignore_username_case={{usersync_ldap_ignore_username_case}}
    force_username_lowercase={{usersync_ldap_force_username_lowercase}}
    force_username_uppercase={{usersync_ldap_force_username_uppercase}}
    search_bind_authentication={{usersync_ldap_search_bind_authentication}}
    subgroups={{usersync_ldap_subgroups}}
    nested_members_search_depth={{usersync_ldap_nested_members_search_depth}}
    follow_referrals={{usersync_ldap_follow_referrals}}
    debug={{usersync_ldap_debug}}
    debug_level={{usersync_ldap_debug_level}}
    trace_level={{usersync_ldap_trace_level}}
    [[[users]]]
      user_filter={{usersync_ldap_user_searchfilter}}
      user_name_attr={{usersync_ldap_user_name_attribute}}
    [[[groups]]]
     {% if usersync_ldap_group_searchenabled %}
      group_filter={{usersync_ldap_group_searchfilter}}
      group_name_attr={{usersync_ldap_group_name_attribute}}
      group_member_attr={{usersync_ldap_group_member_attribute}}
     {% else %}
      ## group_filter="objectclass=*"
      ## group_name_attr=cn
      ## group_member_attr=members
     {% endif %}
    [[[ldap_servers]]]
      ## [[[[mycompany]]]]
        ## base_dn="DC=mycompany,DC=com"
        ## ldap_url=ldap://auth.mycompany.com
        ## nt_domain=mycompany.com
        ## ldap_cert=
        ## use_start_tls=true
        ## bind_dn="CN=ServiceAccount,DC=mycompany,DC=com"
        ## bind_password=
        ## bind_password_script=
        ## ldap_username_pattern="uid=username,ou=People,dc=mycompany,dc=com"
        ## search_bind_authentication=true
        ## follow_referrals=false
        ## debug=false
        ## debug_level=255
        ## trace_level=0
        ## [[[[[users]]]]]
          ## user_filter="objectclass=Person"
          ## user_name_attr=sAMAccountName
        ## [[[[[groups]]]]]
          ## group_filter="objectclass=groupOfNames"
          ## group_name_attr=cn  
   {% else %}
    # The search base for finding users and groups
    ## base_dn="DC=mycompany,DC=com"

    # URL of the LDAP server
    ## ldap_url=ldap://auth.mycompany.com

    # The NT domain used for LDAP authentication
    ## nt_domain=mycompany.com

    # A PEM-format file containing certificates for the CA's that
    # Hue will trust for authentication over TLS.
    # The certificate for the CA that signed the
    # LDAP server certificate must be included among these certificates.
    # See more here http://www.openldap.org/doc/admin24/tls.html.
    ## ldap_cert=
    ## use_start_tls=true

    # Distinguished name of the user to bind as -- not necessary if the LDAP server
    # supports anonymous searches
    ## bind_dn="CN=ServiceAccount,DC=mycompany,DC=com"

    # Password of the bind user -- not necessary if the LDAP server supports
    # anonymous searches
    ## bind_password=

    # Execute this script to produce the bind user password. This will be used
    # when `bind_password` is not set.
    ## bind_password_script=

    # Pattern for searching for usernames -- Use (username) for the parameter
    # For use when using LdapBackend for Hue authentication
    ## ldap_username_pattern="uid=(username),ou=People,dc=mycompany,dc=com"

    # Create users in Hue when they try to login with their LDAP credentials
    # For use when using LdapBackend for Hue authentication
    ## create_users_on_login = true

    # Synchronize a users groups when they login
    ## sync_groups_on_login=false

    # TODO Add login_groups
    # A comma-separated list of Ldap groups with users that can login
    ## login_groups=

    # Ignore the case of usernames when searching for existing users in Hue.
    ## ignore_username_case=true

    # Force usernames to lowercase when creating new users from LDAP.
	# Takes precedence over force_username_uppercase
    ## force_username_lowercase=true

	# Force usernames to uppercase, cannot be combined with force_username_lowercase
    ## force_username_uppercase=false
	
    # Use search bind authentication.
    ## search_bind_authentication=true

    # Choose which kind of subgrouping to use: nested or suboordinate (deprecated).
    ## subgroups=suboordinate

    # Define the number of levels to search for nested members.
    ## nested_members_search_depth=10

    # Whether or not to follow referrals
    ## follow_referrals=false

    # Enable python-ldap debugging.
    ## debug=false

    # Sets the debug level within the underlying LDAP C lib.
    ## debug_level=255

    # Possible values for trace_level are 0 for no logging, 1 for only logging the method calls with arguments,
    # 2 for logging the method calls with arguments and the complete results and 9 for also logging the traceback of method calls.
    ## trace_level=0

    [[[users]]]

      # Base filter for searching for users
      ## user_filter="objectclass=*"

      # The username attribute in the LDAP schema
      ## user_name_attr=sAMAccountName

    [[[groups]]]

      # Base filter for searching for groups
      ## group_filter="objectclass=*"

      # The group name attribute in the LDAP schema
      ## group_name_attr=cn

      # The attribute of the group object which identifies the members of the group
      ## group_member_attr=members

    [[[ldap_servers]]]

      ## [[[[mycompany]]]]

        # The search base for finding users and groups
        ## base_dn="DC=mycompany,DC=com"

        # URL of the LDAP server
        ## ldap_url=ldap://auth.mycompany.com

        # The NT domain used for LDAP authentication
        ## nt_domain=mycompany.com

        # A PEM-format file containing certificates for the CA's that
        # Hue will trust for authentication over TLS.
        # The certificate for the CA that signed the
        # LDAP server certificate must be included among these certificates.
        # See more here http://www.openldap.org/doc/admin24/tls.html.
        ## ldap_cert=
        ## use_start_tls=true

        # Distinguished name of the user to bind as -- not necessary if the LDAP server
        # supports anonymous searches
        ## bind_dn="CN=ServiceAccount,DC=mycompany,DC=com"

        # Password of the bind user -- not necessary if the LDAP server supports
        # anonymous searches
        ## bind_password=

        # Execute this script to produce the bind user password. This will be used
        # when `bind_password` is not set.
        ## bind_password_script=

        # Pattern for searching for usernames -- Use username for the parameter
        # For use when using LdapBackend for Hue authentication
        ## ldap_username_pattern="uid=username,ou=People,dc=mycompany,dc=com"

        ## Use search bind authentication.
        ## search_bind_authentication=true

        # Whether or not to follow referrals
        ## follow_referrals=false

        # Enable python-ldap debugging.
        ## debug=false

        # Sets the debug level within the underlying LDAP C lib.
        ## debug_level=255

        # Possible values for trace_level are 0 for no logging, 1 for only logging the method calls with arguments,
        # 2 for logging the method calls with arguments and the complete results and 9 for also logging the traceback of method calls.
        ## trace_level=0

        ## [[[[[users]]]]]

          # Base filter for searching for users
          ## user_filter="objectclass=Person"

          # The username attribute in the LDAP schema
          ## user_name_attr=sAMAccountName

        ## [[[[[groups]]]]]

          # Base filter for searching for groups
          ## group_filter="objectclass=groupOfNames"

          # The username attribute in the LDAP schema
          ## group_name_attr=cn
   {% endif %}

   # TODO Add [[vcs]] module
   # Configuration options for specifying the Source Version Control.
   # ----------------------------------------------------------------
   [[vcs]]

     ## [[[git-read-only]]]
        ## Base URL to Remote Server
        # remote_url=https://github.com/cloudera/hue/tree/master

        ## Base URL to Version Control API
        # api_url=https://api.github.com
     ## [[[github]]]

        ## Base URL to Remote Server
        # remote_url=https://github.com/cloudera/hue/tree/master

        ## Base URL to Version Control API
        # api_url=https://api.github.com

        # These will be necessary when you want to write back to the repository.
        ## Client ID for Authorized Application
        # client_id=

        ## Client Secret for Authorized Application
        # client_secret=
     ## [[[svn]]
        ## Base URL to Remote Server
        # remote_url=https://github.com/cloudera/hue/tree/master

        ## Base URL to Version Control API
        # api_url=https://api.github.com

        # These will be necessary when you want to write back to the repository.
        ## Client ID for Authorized Application
        # client_id=

        ## Client Secret for Authorized Application
        # client_secret=

  # Configuration options for specifying the Desktop Database. For more info,
  # see http://docs.djangoproject.com/en/1.4/ref/settings/#database-engine
  # ------------------------------------------------------------------------
  [[database]]
    # Database engine is typically one of:
    # postgresql_psycopg2, mysql, sqlite3 or oracle.
    #
    # Note that for sqlite3, 'name', below is a path to the filename. For other backends, it is the database name.
    # Note for Oracle, options={"threaded":true} must be set in order to avoid crashes.
    # Note for Oracle, you can use the Oracle Service Name by setting "host=" and "port=" and then "name=host:port/service_name".
    # Note for MariaDB use the 'mysql' engine.
   {% if metastore_db_flavor == 'sqlite3' %}
    ## engine=sqlite3
    ## host=
    ## port=
    ## user=
    ## password=
    # Execute this script to produce the database password. This will be used when 'password' is not set.
    ## password_script=/path/script
    ## name=desktop/desktop.db
    ## options={}
   {% else %}
    engine={{metastore_db_flavor}}
    host={{metastore_db_host}}
    port={{metastore_db_port}}
    user={{metastore_db_user}}
    {% if metastore_db_password != '' %}
    password={{metastore_db_password}}
    ## password_script={{metastore_db_password_script}}
    {% else %}
    ## password={{metastore_db_password}}
    password_script={{metastore_db_password_script}}
    {% endif %}
    name={{metastore_db_name}}
    options={{metastore_db_options}}
   {% endif %}
  # Configuration options for specifying the Desktop session.
  # For more info, see https://docs.djangoproject.com/en/1.4/topics/http/sessions/
  # ------------------------------------------------------------------------
  [[session]]
    # TODO Add cookie_name
    # The name of the cookie to use for sessions.
    # This can have any value that is not used by the other cookie names in your application.
    ## cookie_name=sessionid

    # TODO Add enable_test_cookie
    # Configuration to determine whether test cookie should be added determine whether the user's browser supports cookies
    # Should be disabled if django_session table is growing rapidly , Default value is true
    ## enable_test_cookie=true

    # The cookie containing the users' session ID will expire after this amount of time in seconds.
    # Default is 2 weeks.
    ttl={{desktop_session_ttl}}

    # The cookie containing the users' session ID will be secure.
    # Should only be enabled with HTTPS.
    secure={{desktop_session_secure}}

    # The cookie containing the users' session ID will use the HTTP only flag.
    http_only={{desktop_session_http_only}}

    # Use session-length cookies. Logs out the user when she closes the browser window.
    expire_at_browser_close={{desktop_session_expire_at_browser_close}}

    # TODO Add concurrent_user_session_limit
    # If set, limits the number of concurrent user sessions. 1 represents 1 browser session per user. Default: 0 (unlimited sessions per user)
    ## concurrent_user_session_limit=0

    # TODO Add trusted_origins
    # A list of hosts which are trusted origins for unsafe requests. See django's CSRF_TRUSTED_ORIGINS for more information
    ## trusted_origins=.cloudera.com

  # Configuration options for connecting to an external SMTP server
  # ------------------------------------------------------------------------
  [[smtp]]

    # The SMTP server information for email notification delivery
    host={{desktop_smtp_host}}
    port={{desktop_smtp_port}}
    user={{desktop_smtp_user}}
    password={{desktop_smtp_password}}

    # Whether to use a TLS (secure) connection when talking to the SMTP server
    tls={{desktop_smtp_tls}}

    # Default email address to use for various automated notification from Hue
    default_from_email={{desktop_smtp_default_from_email}}

  # TODO Add [[knox]] module
  # Configuration options for KNOX integration for secured CDPD cluster
  # ------------------------------------------------------------------------
  [[knox]]

    # This is a list of hosts that knox proxy requests can come from
    ## knox_proxyhosts="server1.domain.com,server2.domain.com"
    # List of Kerberos principal name which is allowed to impersonate others
    ## knox_principal=knox1,knox2
    # Comma separated list of strings representing the ports that the Hue server can trust as knox port.
    ## knox_ports=80,8443

  # Configuration options for Kerberos integration for secured Hadoop clusters
  # ------------------------------------------------------------------------
  [[kerberos]]

   {% if security_enabled %}
    # Path to Hue's Kerberos keytab file
    hue_keytab={{hue_keytab}}
    # Kerberos principal name for Hue
    hue_principal={{hue_principal}}
    # Path to kinit
    kinit_path={{kinit_path}}
	
   {% else %}
    # Path to Hue's Kerberos keytab file
    ## hue_keytab=
    # Kerberos principal name for Hue
    ## hue_principal=hue/hostname.foo.com
    # Frequency in seconds with which Hue will renew its keytab  TODO Add
    ## REINIT_FREQUENCY=3600
    # Path to keep Kerberos credentials cached  TODO Add
    ## ccache_path=/var/run/hue/hue_krb5_ccache
    # Path to kinit
    ## kinit_path=/path/to/kinit
    # Set to false if renew_lifetime in krb5.conf is set to 0m  TODO Add
    ## krb5_renewlifetime_enabled=true

    # Mutual authentication from the server, attaches HTTP GSSAPI/Kerberos Authentication to the given Request object  TODO Add
    ## mutual_authentication="OPTIONAL" or "REQUIRED" or "DISABLED"
   {% endif %}

  # Configuration options for using OAuthBackend (Core) login
  # ------------------------------------------------------------------------
  [[oauth]]
    # The Consumer key of the application
    ## consumer_key={{desktop_oauth_consumer_key}}

    # The Consumer secret of the application
    ## consumer_secret={{desktop_oauth_consumer_secret}}

    # The Request token URL
    ## request_token_url={{desktop_oauth_request_token_url}}

    # The Access token URL
    ## access_token_url={{desktop_oauth_access_token_url}}

    # The Authorize URL
    ## authenticate_url={{desktop_oauth_authenticate_url}}

  # TODO Add [[oidc]] module
  # Configuration options for using OIDCBackend (Core) login for SSO
  # ------------------------------------------------------------------------
  [[oidc]]
    # The client ID as relay party set in OpenID provider
    ## oidc_rp_client_id=XXXXXXXXXXXXXXXXXXXXX

    # The client secret as relay party set in OpenID provider
    ## oidc_rp_client_secret=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

    # The OpenID provider authoriation endpoint
    ## oidc_op_authorization_endpoint=https://keycloak.example.com/auth/realms/Cloudera/protocol/openid-connect/auth

    # The OpenID provider token endpoint
    ## oidc_op_token_endpoint=https://keycloak.example.com/auth/realms/cloudera/protocol/openid-connect/token

    # The OpenID provider user info endpoint
    ## oidc_op_user_endpoint=https://keycloak.example.com/auth/realms/cloudera/protocol/openid-connect/userinfo

    # The OpenID provider signing key in PEM or DER format
    ## oidc_rp_idp_sign_key=/path/to/key_file

    # The OpenID provider authoriation endpoint
    ## oidc_op_jwks_endpoint=https://keycloak.example.com/auth/realms/Cloudera/protocol/openid-connect/certs

    # Whether Hue as OpenID Connect client verify SSL cert
    ## oidc_verify_ssl=true

    # As relay party Hue URL path to redirect to after login
    ## login_redirect_url=https://localhost:8888/oidc/callback/

    # The OpenID provider URL path to redirect to after logout
    ## logout_redirect_url=https://keycloak.example.com/auth/realms/cloudera/protocol/openid-connect/logout

    # As relay party Hue URL path to redirect to after login
    ## login_redirect_url_failure=https://localhost:8888/hue/oidc_failed/

    # Create a new user from OpenID Connect on login if it doesn't exist
    ## create_users_on_login=true

    # When creating a new user, which 'claims' attribute from the OIDC provider to be used for creating the username.
    #      Default to 'preferred_username'. Possible values include: 'email'
    ## oidc_username_attribute=preferred_username

    # The group of users will be created and updated as superuser. To use this feature, setup in Keycloak:
    # 1. add the name of the group here
    # 2. in Keycloak, go to your_realm --> your_clients --> Mappers, add a mapper
    #      Mapper Type: Group Membership (this is predefined mapper type)
    #      Token Claim Name: group_membership (required exact string)
    ## superuser_group=hue_superusers

  # Configuration options for Metrics
  # ------------------------------------------------------------------------
  [[metrics]]

    # Enable the metrics URL "/desktop/metrics"
    enable_web_metrics={{desktop_metrics_enable_web_metrics}}

    # If specified, Hue will write metrics to this file.
    location={{desktop_metrics_location}}

    # Time in milliseconds on how frequently to collect metrics
    collection_interval={{desktop_metrics_collection_interval}}

  # TODO Add [[slack]] module
  # Configuration options for Slack
  # ------------------------------------------------------------------------
  [[slack]]
    # Slack credentials
    ## slack_client_id=
    ## slack_client_secret=
    ## slack_verification_token=
    ## slack_bot_user_token=

    # Enables Slack application API endpoints
    ## is_enabled=true

    # Enables direct sharing from Editor to Slack
    ## share_from_editor=true

  # TODO Add [[tracing]] module
  # Configuration options for the request Tracing
  # ------------------------------------------------------------------------
  [[tracing]]
    ## If tracing is enabled.
    # enabled=false

    ## Trace all the requests instead of a few specific ones like the SQL Editor. Much noisiers.
    # trace_all=false

  # TODO Add [[task_server]] module
  # Configuration options for the Task Server
  # ------------------------------------------------------------------------
  [[task_server]]

    # If resource intensive or blocking can be delegated to an already running task server.
    ## enabled=False

    # Switch on the integration with the Task Scheduler.
    ## beat_enabled=False

    # Number of query results rows to fetch into the result storage.
    ## fetch_result_limit=2000

    # Django file storage class to use to temporarily store query results
    ## result_storage='{"backend": "django.core.files.storage.FileSystemStorage", "properties": {"location": "./logs"}}'

    # How the task server and tasks communicate.
    ## broker_url=amqp://guest:guest@localhost//

    # Where to store task results. Defaults to local file system path. Celery comes with a several other backends.
    ## celery_result_backend=file:///$HUE_ROOT/logs

    # Default options provided to the task server at startup.
    ## celeryd_opts='--time-limit=300'

    # Django cache to use to store temporarily used data during query execution. This is in addition to result_file_storage and result_backend.
    ## execution_storage='{"BACKEND": "django.core.cache.backends.locmem.LocMemCache", "LOCATION": "celery-hue"}'

  # TODO Add [[gc_accounts]] module
  # Settings for the Google Cloud lib
  # ------------------------------------------------------------------------
  [[gc_accounts]]
     [[[default]]]
        # The JSON credentials to authenticate to Google Cloud e.g. '{ "type": "service_account", "project_id": .... }'
        # json_credentials=None

  # TODO Add [[raz]] module
  ## Configuration for RAZ service integration
  # ------------------------------------------------------------------------
  [[raz]]
    ## Turns on the integration as ready to use
    # is_enabled=false

    ## Endpoint to contact
    # api_url=https://localhost:8080

    ## How to authenticate against: KERBEROS or JWT (not supported yet)
    # api_authentication=KERBEROS

    ## Autocreate the user home directory in the remote home storage path.
    # autocreate_user_dir=true

###########################################################################
# Settings to configure the snippets available in the Notebook
###########################################################################

[notebook]

  ## Show the notebook menu or not
  show_notebooks={{notebook_show_notebooks}}

  # TODO Add enable_external_statements
  ## Flag to enable the selection of queries from files, saved queries into the editor or as snippet.
  # enable_external_statements=false

  ## Flag to enable the bulk submission of queries as a background task through Oozie.
  enable_batch_execute={{notebook_enable_batch_execute}}

  # TODO Add enable_sql_indexer
  ## Flag to turn on the SQL indexer.
  # enable_sql_indexer=false

  # TODO Add enable_presentation
  ## Flag to turn on the Presentation mode of the editor.
  # enable_presentation=true

  ## Flag to enable the SQL query builder of the table assist.
  enable_query_builder={{notebook_enable_query_builder}}

  ## Flag to enable the creation of a coordinator for the current SQL query.
  enable_query_scheduling={{notebook_enable_query_scheduling}}

  # TODO Del github_remote_url
  ## Base URL to Remote GitHub Server
  github_remote_url={{notebook_github_remote_url}}

  # TODO Del github_api_url
  ## Base URL to GitHub API
  github_api_url={{notebook_github_api_url}}

  # TODO Del github_client_id
  ## Client ID for Authorized GitHub Application
  github_client_id={{notebook_github_client_id}}

  # TODO Del github_client_secret
  ## Client Secret for Authorized GitHub Application
  github_client_secret={{notebook_github_client_secret}}

  ## Main flag to override the automatic starting of the DBProxy server.
  enable_dbproxy_server={{notebook_enable_dbproxy_server}}

  # TODO Add dbproxy_extra_classpath
  ## Classpath to be appended to the default DBProxy server classpath.
  # dbproxy_extra_classpath=

  # TODO Add interpreters_shown_on_wheel
  ## Comma separated list of interpreters that should be shown on the wheel. This list takes precedence over the
  ## order in which the interpreter entries appear. Only the first 5 interpreters will appear on the wheel.
  # interpreters_shown_on_wheel=

  # TODO Add default_limit
  ## Default limit to use in SELECT statements if not present. Set to 0 to disable.
  # default_limit=5000

  # One entry for each type of snippet. The first 5 will appear in the wheel.
  [[interpreters]]
    # Define the name and how to connect and execute the language.
    # https://docs.gethue.com/administrator/configuration/editor/

    # [[[mysql]]]
    #   name=MySQL
    #   interface=sqlalchemy
    #   ## https://docs.sqlalchemy.org/en/latest/dialects/mysql.html
    #   options='{"url": "mysql://root:secret@database:3306/hue"}'
    #   ## options='{"url": "mysql://${USER}:${PASSWORD}@localhost:3306/hue"}'

  {% if hue_hive_module_enabled == 'Yes' %}
    # [[[hive]]]
    #   name=Hive
    #   interface=hiveserver2
    [[[hive]]]
      # The name of the snippet.
      name=Hive
      # The backend connection to use to communicate with the server.
      interface=hiveserver2

    # [[[hplsql]]]
    #   name=Hplsql
    #   interface=hiveserver2

    # [[[llap]]]
    #   name=LLAP
    #   interface=hiveserver2

    # [[[impala]]]
    #   name=Impala
    #   interface=hiveserver2
    {% if hue_impala_module_enabled == 'Yes' %}
    [[[impala]]]
      name=Impala
      interface=hiveserver2
    {% endif %}

    # [[[sparksql]]]
    #   name=Spark Sql
    #   interface=sqlalchemy
    #   options='{"url": "hive://user:password@localhost:10000/database"}'
    {% if hue_spark_module_enabled == 'Yes' %}
    [[[sparksql]]]
      name=SparkSql
      interface=hiveserver2
    {% endif %}
  {% endif %}
  {% if hue_spark_module_enabled == 'Yes' %}
    # [[[sparksql]]]
    #   name=SparkSql
    #   interface=livy

    # [[[spark]]]
    #   name=Scala
    #   interface=livy
    [[[spark]]]
      name=Scala
      interface=livy

    # [[[pyspark]]]
    #   name=PySpark
    #   interface=livy
    [[[pyspark]]]
      name=PySpark
      interface=livy

    # [[[r]]]
    #   name=R
    #   interface=livy
    [[[r]]]
      name=R
      interface=livy

    # [[jar]]]
    #   name=Spark Submit Jar
    #   interface=livy-batch
    [[[jar]]]
      name=Spark Submit Jar
      interface=livy-batch

    # [[[py]]]
    #   name=Spark Submit Python
    #   interface=livy-batch
    [[[py]]]
      name=Spark Submit Python
      interface=livy-batch
  {% endif %}
  {% if hue_oozie_module_enabled == 'Yes' %}
    {% if hue_pig_module_enabled == 'Yes' %}
    # [[[pig]]]
    #   name=Pig
    #   interface=oozie
    [[[pig]]]
      name=Pig
      interface=oozie
    {% endif %}
    # [[[java]]]
    #   name=Java
    #   interface=oozie
    [[[java]]]
      name=Java
      interface=oozie
    {% if hue_spark_module_enabled == 'Yes' %}
    # [[[spark2]]]
    #   name=Spark
    #   interface=oozie
    [[[spark2]]]
      name=Spark
      interface=oozie
    {% endif %}
  {% endif %}

    # [[[text]]]
    #   name=Text
    #   interface=text

    # [[[markdown]]]
    #   name=Markdown
    #   interface=text

  {% if hue_rdbms_module_enabled == 'Yes' %}

    {% if rdbms_mysql_engine %}
    [[[mysql]]]
      name=MySQL
      interface=rdbms
    {% endif %}

    # [[[sqlite]]]
    #   name = SQLite
    #   interface=rdbms
    {% if rdbms_sqlite_engine %}
    [[[sqlite]]]
      name = SQLite
      interface=rdbms
    {% endif %}

    # [[[postgresql]]]
    #   name = postgresql
    #   interface=sqlalchemy
    #   options='{"url": "postgresql://hue:hue@host:5432/hue"}'
    {% if rdbms_postgresql_engine %}
    [[[postgresql]]]
      name = PostgreSQL
      interface=rdbms
    {% endif %}

    # [[[druid]]]
    #   name = Druid
    #   interface=sqlalchemy
    #   options='{"url": "druid://host:8082/druid/v2/sql/"}'

    # [[[oracle]]]
    #   name = Oracle
    #   interface=rdbms
    {% if rdbms_oracle_engine %}
    [[[oracle]]]
      name = Oracle
      interface=rdbms
    {% endif %}
  {% endif %}

    # [[[solr]]]
    #   name = Solr SQL
    #   interface=solr
    #   ## Name of the collection handler
    #   options='{"collection": "default"}'
  {% if hue_solr_module_enabled == 'Yes' %}
    [[[solr]]]
      name = Solr SQL
      interface=solr
      ## Name of the collection handler
      # options='{"collection": "default"}'
  {% endif %}

    # [[[mapreduce]]]
    #   name=MapReduce
    #   interface=oozie

    # [[[sqoop1]]]
    #   name=Sqoop1
    #   interface=oozie

    # [[[distcp]]]
    #   name=Distcp
    #   interface=oozie

    # [[[shell]]]
    #   name=Shell
    #   interface=oozie

    # [[[trino]]]
    #    name=Trino SQL
    #    interface=jdbc
    #	 interface=trino
    #    options='{"url": "jdbc:trino://ip:port/catalog", "driver": "io.trino.jdbc.TrinoDriver","user": "username", "password": ""}'
    # options=
  {% if notebook_integration_trino == 'true' %}
    [[[trino]]]
      name=Trino SQL
      interface=jdbc
      options='{"url": "{{notebook_integration_trino_url}}", "driver": "io.trino.jdbc.TrinoDriver","user": "trino", "password": ""}'
  {% endif %}

    # [[[presto]]]
    # name=Presto SQL
    # interface=presto
    # ## Specific options for connecting to the Presto server.
    # ## The JDBC driver presto-jdbc.jar need to be in the CLASSPATH environment variable.
    # ## If 'user' and 'password' are omitted, they will be prompted in the UI.
    # options='{"url": "jdbc:presto://ip:port/catalog/schema", "driver": "io.prestosql.jdbc.PrestoDriver", "user": "root", "password": "root"}'
    # ## Impersonation on.
    # # options='{"url": "presto://ip:port/catalog/schema", "has_impersonation": true}'
    # ## Kerberos.
    # # options='{"url": "presto://ip:port/catalog/schema?KerberosKeytabPath=/path/to/keytab&amp;KerberosPrincipal=principal&amp;KerberosRemoteServiceName=service&amp;protocol=https"'
    # ## LDAPS enabled over HTTPS.
    # # options='{"url": "presto://username:password@ip:port/catalog/schema","connect_args":"{\"protocol\": \"https\"}"}'
    # ## Presto Session properties along with HTTPS.
    # # options='{"url": "presto://username:password@ip:port/catalog/schema","connect_args":"{\"protocol\": \"https\", \"session_props\": {\"query_max_run_time\": \"1m\"}}"}'
    # ## Presto Session properties when HTTPS is not enabled.
    # # options='{"url": "presto://username:password@ip:port/catalog/schema","connect_args":"{\"session_props\": {\"query_max_run_time\": \"1m\"}}"}'
    # options=

    # [[[dasksql]]]
    # name=Dask-SQL
    # interface=sqlalchemy
    # ## Specific options for connecting to the dask-sql server.
    # ## Please note, that dask-sql uses the presto protocol.
    # # options='{"url": "presto://ip:port/catalog/schema"}'

    # [[[clickhouse]]]
    # name=ClickHouse
    # interface=sqlalchemy
    # e.g. clickhouse://user:password@ip:8124/test?protocol=https
    # options='{"url": "clickhouse://ip:8123"}'
    # options=

    # [[[vertica]]]
    # name=Vertica
    # interface=jdbc
    # ## Specific options for connecting to a Vertica server.
    # ## The JDBC driver vertica-jdbc-*.jar and its related jars need to be in the CLASSPATH environment variable.
    # ## If 'user' and 'password' are omitted, they will be prompted in the UI.
    # options='{"url": "jdbc:vertica://ip:5434", "driver": "com.vertica.jdbc.Driver"}'
    # options=

    ## Define which query and table examples can be automatically setup for the available dialects.
    # [[examples]]
    ## If installing the examples automatically at startup.
    # auto_load=false
    ## If automatically loading the dialect example at Editor opening.
    # auto_open=false
    ## Names of the saved queries to install. All if empty.
    # queries=
    ## Names of the tables to install. All if empty.
    # tables=

    # [[[mysql]]]
    #   name=MySql JDBC
    #   interface=jdbc
    #   ## Specific options for connecting to the server.
    #   ## The JDBC connectors, e.g. mysql.jar, need to be in the CLASSPATH environment variable.
    #   ## If 'user' and 'password' are omitted, they will be prompted in the UI.
    #   options='{"url": "jdbc:mysql://ip:port/hue", "driver": "com.mysql.jdbc.Driver", "user": "root", "password": "root"}'
    # options=

# TODO Add [dashboard] module
###########################################################################
# Settings to configure your Analytics Dashboards
###########################################################################

[dashboard]

  # Activate the Dashboard link in the menu.
  ## is_enabled=true

  # Activate the SQL Dashboard (beta).
  ## has_sql_enabled=false

  # Activate the Query Builder (beta).
  ## has_query_builder_enabled=false

  # Activate the static report layout (beta).
  ## has_report_enabled=false

  # Activate the new grid layout system.
  ## use_gridster=true

  # Activate the widget filter and comparison (beta).
  ## has_widget_filter=false

  # Activate the tree widget (to drill down fields as dimensions, alpha).
  ## has_tree_widget=false

  # Setting this value to true opens up for possible xss attacks.
  ## allow_unsecure_html=false

  [[engines]]

    #  [[[solr]]]
    #  Requires Solr 6+
    ##  analytics=true
    ##  nesting=false

    #  [[[sql]]]
    ##  analytics=true
    ##  nesting=false

###########################################################################
# Settings to configure your Hadoop cluster.
###########################################################################

[hadoop]

  # Configuration for HDFS NameNode
  # ------------------------------------------------------------------------
  [[hdfs_clusters]]
    # HA support by using HttpFs

    [[[default]]]
      # Enter the filesystem uri
      fs_defaultfs={{namenode_address}}

      # NameNode logical name.
      {% if dfs_ha_enabled %}
      logical_name=hdfs://{{logical_name}}
      {% else %}
      ## logical_name=
      {% endif %}

      # Use WebHdfs/HttpFs as the communication mechanism.
      # Domain should be the NameNode or HttpFs host.
      # Default port is 14000 for HttpFs.
      webhdfs_url={{webhdfs_url}}

      # Change this if your HDFS cluster is Kerberos-secured
      {% if security_enabled %}
      security_enabled={{security_enabled}}
      {% else %}
      ## security_enabled=false
      {% endif %}

      # In secure mode (HTTPS), if SSL certificates from YARN Rest APIs
      # have to be verified against certificate authority
      ## ssl_cert_ca_verify={{hadoop_ssl_cert_ca_verify}}

      # Directory of the Hadoop configuration
      hadoop_conf_dir={{hadoop_conf_dir}}

      # TODO Add is_enabled
      # Whether Hue should list this HDFS cluster. For historical reason there is no way to disable HDFS.
      ## is_enabled=true

  # Configuration for YARN (MR2)
  # ------------------------------------------------------------------------
  [[yarn_clusters]]

    [[[default]]]
      # Enter the host on which you are running the ResourceManager
      resourcemanager_host={{resourcemanager_host1}}

      # The port where the ResourceManager IPC listens on
      resourcemanager_port={{resourcemanager_port}}

      # Whether to submit jobs to this cluster
      submit_to=True

      # Resource Manager logical name (required for HA)
      {% if resourcemanager_ha_enabled %}
      logical_name={{logical_name}}
      {% else %}
      ## logical_name=
      {% endif %}

      # Change this if your YARN cluster is Kerberos-secured
      {% if security_enabled %}
      security_enabled={{security_enabled}}
      {% else %}
      ## security_enabled=false
      {% endif %}

      # URL of the ResourceManager API
      resourcemanager_api_url={{resourcemanager_api_url1}}

      # URL of the ProxyServer API
      proxy_api_url={{proxy_api_url1}}

      # URL of the HistoryServer API
      history_server_api_url={{history_server_api_url}}

      # URL of the Spark History Server
      spark_history_server_url=http://localhost:18088

      # TODO Add spark_history_server_security_enabled
      # Change this if your Spark History Server is Kerberos-secured
      ## spark_history_server_security_enabled=false

      # In secure mode (HTTPS), if SSL certificates from YARN Rest APIs
      # have to be verified against certificate authority
      ## ssl_cert_ca_verify={{hadoop_ssl_cert_ca_verify}}

    # HA support by specifying multiple clusters.
    # Redefine different properties there.
    # e.g.

    {% if resourcemanager_ha_enabled %}
    [[[ha]]]
      # Resource Manager logical name (required for HA)
      logical_name={{logical_name}}

      # Un-comment to enable
      submit_to=True

      # URL of the ResourceManager API
      resourcemanager_api_url={{resourcemanager_api_url2}}
      resourcemanager_host={{resourcemanager_host2}}
      resourcemanager_port={{resourcemanager_port}}
      proxy_api_url={{proxy_api_url2}}
      history_server_api_url={{history_server_api_url}}
      spark_history_server_url={{spark_history_server_url}}
    {% else %}
    # [[[ha]]]
      # Resource Manager logical name (required for HA)
      ## logical_name=my-rm-name

      # Un-comment to enable
      ## submit_to=True

      # URL of the ResourceManager API
      ## resourcemanager_api_url=http://localhost:8088

      # ...
    {% endif %}

  # TODO Del [[mapred_clusters]] module
  # Configuration for MapReduce (MR1)
  # ------------------------------------------------------------------------
  [[mapred_clusters]]

    [[[default]]]
      # Enter the host on which you are running the Hadoop JobTracker
      ## jobtracker_host=localhost

      # The port where the JobTracker IPC listens on
      ## jobtracker_port=8021

      # JobTracker logical name for HA
      ## logical_name=

      # Thrift plug-in port for the JobTracker
      ## thrift_port=9290

      # Whether to submit jobs to this cluster
      submit_to=False

      # Change this if your MapReduce cluster is Kerberos-secured
      ## security_enabled=false

    # HA support by specifying multiple clusters
    # e.g.

    # [[[ha]]]
      # Enter the logical name of the JobTrackers
      ## logical_name=my-jt-name


###########################################################################
# Settings to configure Beeswax with Hive
###########################################################################

[beeswax]

  # Use SASL framework to establish connection to host.
  use_sasl={{hive_use_sasl}}

  # Host where HiveServer2 is running.
  # If Kerberos security is enabled, use fully-qualified domain name (FQDN).
  ## hive_server_host=localhost
  hive_server_host={{hive_server_host}}

  # Port where HiveServer2 Thrift server runs on.
  ## hive_server_port=10000
  hive_server_port={{hive_server_port}}

  # TODO Add hive_server_http_port
  # Http thrift port for HiveServer2.
  ## hive_server_http_port=10001

  # TODO Add llap_server_host
  # Host where LLAP is running
  ## llap_server_host=localhost

  # TODO Add llap_server_port
  # LLAP binary thrift port
  ## llap_server_port=10500

  # TODO Add llap_server_thrift_port
  # LLAP HTTP Thrift port
  ## llap_server_thrift_port=10501

  # Alternatively, use Service Discovery for LLAP (Hive Server Interactive) and/or Hiveserver2, this will override server and thrift port

  # TODO Add hive_discovery_llap
  # Whether to use Service Discovery for LLAP
  ## hive_discovery_llap=true

  # TODO Add hive_discovery_llap_ha
  # is llap (hive server interactive) running in an HA configuration (more than 1)
  # important as the zookeeper structure is different
  ## hive_discovery_llap_ha=false

  # TODO Add hive_discovery_llap_znode
  # Shortcuts to finding LLAP znode Key
  # Non-HA - hiveserver-interactive-site - hive.server2.zookeeper.namespace ex hive2 = /hive2
<!--  # HA-NonKerberized - <llap_app_name>_llap ex app name llap0 = /llap0_llap-->
<!--  # HA-Kerberized - <llap_app_name>_llap-sasl ex app name llap0 = /llap0_llap-sasl-->
  ## hive_discovery_llap_znode=/hiveserver2-hive2

  # TODO Add hive_discovery_hs2
  # Whether to use Service Discovery for HiveServer2
  ## hive_discovery_hs2=true

  # TODO Add hive_discovery_hiveserver2_znode
  # Hiveserver2 is hive-site hive.server2.zookeeper.namespace ex hiveserver2 = /hiverserver2
  ## hive_discovery_hiveserver2_znode=/hiveserver2

  # TODO Add cache_timeout
  # Applicable only for LLAP HA
  # To keep the load on zookeeper to a minimum
  # ---- we cache the LLAP activeEndpoint for the cache_timeout period
  # ---- we cache the hiveserver2 endpoint for the length of session
  # configurations to set the time between zookeeper checks
  ## cache_timeout = 60

  # TODO Add hive_metastore_host
  # Host where Hive Metastore Server (HMS) is running.
  # If Kerberos security is enabled, the fully-qualified domain name (FQDN) is required.
  ## hive_metastore_host=localhost

  # TODO Add hive_metastore_port
  # Configure the port the Hive Metastore Server runs on.
  ## hive_metastore_port=9083

  # Hive configuration directory, where hive-site.xml is located
  hive_conf_dir={{hive_conf_dir}}

  # Timeout in seconds for thrift calls to Hive service
  server_conn_timeout={{hive_server_conn_timeout}}

  # Choose whether to use the old GetLog() thrift call from before Hive 0.14 to retrieve the logs.
  # If false, use the FetchResults() thrift call from Hive 1.0 or more instead.
  use_get_log_api={{hive_use_get_log_api}}

  # Limit the number of partitions that can be listed.
  list_partitions_limit={{hive_list_partitions_limit}}

  # The maximum number of partitions that will be included in the SELECT * LIMIT sample query for partitioned tables.
  query_partitions_limit={{hive_query_partitions_limit}}

  # TODO Del download_cell_limit
  # A limit to the number of cells (rows * columns) that can be downloaded from a query
  # (e.g. - 10K rows * 1K columns = 10M cells.)
  # A value of -1 means there will be no limit.
  download_cell_limit={{hive_download_cell_limit}}

  # TODO Add download_row_limit
  # A limit to the number of rows that can be downloaded from a query before it is truncated.
  # A value of -1 means there will be no limit.
  ## download_row_limit=100000

  # TODO Add download_bytes_limit
  # A limit to the number of bytes that can be downloaded from a query before it is truncated.
  # A value of -1 means there will be no limit.
  ## download_bytes_limit=-1

  # Hue will try to close the Hive query when the user leaves the editor page.
  # This will free all the query resources in HiveServer2, but also make its results inaccessible.
  close_queries={{hive_close_queries}}

  # TODO Add max_number_of_sessions
  # Hue will use at most this many HiveServer2 sessions per user at a time.
  # For Tez, increase the number to more if you need more than one query at the time, e.g. 2 or 3 (Tez has a maximum of 1 query by session).
  # -1 is unlimited number of sessions.
  ## max_number_of_sessions=1

  # TODO Add close_sessions
  # When set to True, Hue will close sessions created for background queries and open new ones as needed.
  # When set to False, Hue will keep sessions created for background queries opened and reuse them as needed.
  # This flag is useful when max_number_of_sessions != 1
  ## close_sessions=max_number_of_sessions != 1

  # Thrift version to use when communicating with HiveServer2.
  # Version 11 comes with Hive 3.0. If issues, try 7.
  thrift_version={{hive_thrift_version}}

  # A comma-separated list of white-listed Hive configuration properties that users are authorized to set.
  config_whitelist={{hive_config_whitelist}}

  # Override the default desktop username and password of the hue user used for authentications with other services.
  # e.g. Used for LDAP/PAM pass-through authentication.
  {% if hive_server2_authentication.strip() == 'LDAP' %}
  auth_username={{hive_auth_username}}
  auth_password={{hive_auth_password}}
  {% else %}
  ## auth_username={{hive_auth_username}}
  ## auth_password={{hive_auth_password}}
  {% endif %}

  # TODO Add max_catalog_sql_entries
  # Max number of objects (columns, tables, databases) available to list in the left assist, autocomplete, table browser etc.
  # Setting this higher than the default can degrade performance.
  ## max_catalog_sql_entries=5000

  [[ssl]]
    # Path to Certificate Authority certificates.
    ## cacerts={{hive_ssl_cacerts}}

    # Choose whether Hue should validate certificates received from the server.
    ## validate={{hive_ssl_validate}}

# TODO Add [metastore] module
###########################################################################
# Settings to configure Metastore
###########################################################################

[metastore]
  # Flag to turn on the new version of the create table wizard.
  ## enable_new_create_table=true

  # Flag to force all metadata calls (e.g. list tables, table or column details...) to happen via HiveServer2 if available instead of Impala.
  ## force_hs2_metadata=false

  # Choose whether to show the table ERD component. Default false
  ## show_table_erd=false

###########################################################################
# Settings to configure Impala
###########################################################################

[impala]
  # Host of the Impala Server (one of the Impalad)
  ## server_host=localhost

  # Port of the Impala Server
  ## server_port=21050

  # TODO Add proxy_endpoint
  # Endpoint of the Impala Proxy Server, for example: '/endpoint'
  # Note that SERVER_PORT will be used when set.
  ## proxy_endpoint=

  # TODO Add proxy_endpoint
  # URL of the Impala Coordinator Server.
  ## coordinator_url=localhost:25000

  # Kerberos principal
  ## impala_principal=impala/hostname.foo.com

  # Turn on/off impersonation mechanism when talking to Impala
  ## impersonation_enabled=False

  # Number of initial rows of a result set to ask Impala to cache in order
  # to support re-fetching them for downloading them.
  # Set to 0 for disabling the option and backward compatibility.
  ## querycache_rows=50000

  # Timeout in seconds for thrift calls
  ## server_conn_timeout=120

  # Hue will try to close the Impala query when the user leaves the editor page.
  # This will free all the query resources in Impala, but also make its results inaccessible.
  ## close_queries=true

  # If ) 0, the query will be timed out (i.e. cancelled) if Impala does not do any work
  # (compute or send back results) for that query within QUERY_TIMEOUT_S seconds.
  ## query_timeout_s=600

  # If ) 0, the session will be timed out (i.e. cancelled) if Impala does not do any work
  # (compute or send back results) for that session within QUERY_TIMEOUT_S seconds (default 12hours).
  ## session_timeout_s=43200

  # Override the desktop default username and password of the hue user used for authentications with other services.
  # e.g. Used for LDAP/PAM pass-through authentication.
  ## auth_username=hue
  ## auth_password=

  # TODO Add daemon_api_username, daemon_api_password
  # Username and password for Impala Daemon Web interface for getting Impala queries in JobBrowser
  ## daemon_api_username=
  ## daemon_api_password=

  # TODO Add daemon_api_password_script
  # Execute this script to produce the password to avoid entering in clear text
  ## daemon_api_password_script=

  # TODO Add daemon_api_auth_scheme
  # Set to 'digest' when webserver_htpassword_user and webserver_htpassword_password are set for Impala, or set to
  # 'basic' if webserver_require_ldap is set
  ## daemon_api_auth_scheme=digest

  # A comma-separated list of white-listed Impala configuration properties that users are authorized to set.
  ## config_whitelist=debug_action,explain_level,mem_limit,optimize_partition_key_scans,query_timeout_s,request_pool

  # TODO Add impala_conf_dir
  # Path to the impala configuration dir which has impalad_flags file
  ## impala_conf_dir=${HUE_CONF_DIR}/impala-conf

  # TODO Add use_sasl
  # Use SASL framework to establish connection to host.
  ## use_sasl=true

  # TODO Add use_thrift_http
  # Use Thrift over HTTP for the transport mode.
  ## use_thrift_http=false

  # TODO Add user_scratch_dir_permission
  # Due to IMPALA-10272, the importer fails with READ permissions.
  # Setting this to True, means setting the scratch directory and its file to 777 so the importer does not fail with permission issue
  ## user_scratch_dir_permission=false

  [[ssl]]
    # SSL communication enabled for this server.
    ## enabled=false

    # Path to Certificate Authority certificates.
    ## cacerts=/etc/hue/cacerts.pem

    # Choose whether Hue should validate certificates received from the server.
    ## validate=true

###########################################################################
# Settings to configure the Spark application.
###########################################################################

[spark]
  # TODO Del livy_server_host
  # Host address of the Livy Server.
  livy_server_host={{livy_server_host}}

  # TODO Del livy_server_port
  # Port of the Livy Server.
  livy_server_port={{livy_server_port}}

  # TODO Add livy_server_url
  # The Livy Server URL.
  ## livy_server_url=http://localhost:8998

  # TODO Add security_enabled
  # Whether Livy requires client to perform Kerberos authentication.
  ## security_enabled=false

  # TODO Add csrf_enabled
  # Whether Livy requires client to use csrf protection.
  ## csrf_enabled=false

  # TODO Del livy_server_session_kind
  # Configure Livy to start in local 'process' mode, or 'yarn' workers.
  livy_server_session_kind={{livy_server_session_kind}}

  # Host of the Sql Server
  sql_server_host={{spark_thriftserver_host}}

  # Port of the Sql Server
  sql_server_port={{spark_hiveserver2_thrift_port}}

  # TODO Add ssl_cert_ca_verify
  # Choose whether Hue should validate certificates received from the server.
  ## ssl_cert_ca_verify=true

  # TODO Add use_sasl
  # Use SASL framework to establish connection to host.
  ## use_sasl=false


###########################################################################
# Settings to configure the Oozie app
###########################################################################

[oozie]
  # Location on local FS where the examples are stored.
  local_data_dir={{oozie_local_data_dir}}

  # Location on local FS where the data for the examples is stored.
  sample_data_dir={{oozie_sample_data_dir}}

  # Location on HDFS where the oozie examples and workflows are stored.
  remote_data_dir={{oozie_remote_data_dir}}

  # Maximum of Oozie workflows or coodinators to retrieve in one API call.
  oozie_jobs_count={{oozie_jobs_count}}

  # Use Cron format for defining the frequency of a Coordinator instead of the old frequency number/unit.
  enable_cron_scheduling={{oozie_enable_cron_scheduling}}

  ## Flag to enable the saved Editor queries to be dragged and dropped into a workflow.
  enable_document_action={{oozie_enable_document_action}}

  # TODO Add enable_oozie_backend_filtering
  # Flag to enable Oozie backend filtering instead of doing it at the page level in Javascript. Requires Oozie 4.3+.
  ## enable_oozie_backend_filtering=true

  # TODO Add enable_impala_action
  # Flag to enable the Impala action.
  ## enable_impala_action=false

  # TODO Add enable_altus_action
  # Flag to enable the Altus action.
  ## enable_altus_action=false

###########################################################################
# Settings to configure the Filebrowser app
###########################################################################

[filebrowser]
  # Location on local filesystem where the uploaded archives are temporary stored.
  archive_upload_tempdir={{filebrowser_archive_upload_tempdir}}

  # Show Download Button for HDFS file browser.
  show_download_button={{filebrowser_show_download_button}}

  # Show Upload Button for HDFS file browser.
  show_upload_button={{filebrowser_show_upload_button}}

  # TODO Add enable_extract_uploaded_archive
  # Flag to enable the extraction of a uploaded archive in HDFS.
  ## enable_extract_uploaded_archive=true

  # TODO Add redirect_download
<!--  # Redirect client to WebHdfs or S3 for file download. Note: Turning this on will override notebook/redirect_whitelist for user selected file downloads on WebHdfs & S3.-->
  ## redirect_download=false

  # TODO Add remote_storage_home
  # Optionally set this if you want a different home directory path. e.g. s3a://gethue.
  ## remote_storage_home=s3a://gethue


###########################################################################
# Settings to configure Pig
###########################################################################

[pig]
  # Location of piggybank.jar on local filesystem.
  local_sample_dir={{pig_local_sample_dir}}

  # Location piggybank.jar will be copied to in HDFS.
  remote_data_dir={{pig_remote_data_dir}}


###########################################################################
# Settings to configure Sqoop2
###########################################################################

[sqoop]
  # For autocompletion, fill out the librdbms section.

  # TODO Add is_enabled
  # If the Sqoop2 app is enabled. Sqoop2 project is deprecated. Sqoop1 is recommended.
  ## is_enabled=false

  # Sqoop server URL
  ## server_url=http://localhost:12000/sqoop

  # Path to configuration directory
  ## sqoop_conf_dir=/etc/sqoop2/conf

  # TODO Add ssl_cert_ca_verify
  # Choose whether Hue should validate certificates received from the server.
  ## ssl_cert_ca_verify=true

# TODO Add [proxy] module
###########################################################################
# Settings to configure Proxy
###########################################################################

  [proxy]
    # Comma-separated list of regular expressions,
    # which match 'host:port' of requested proxy target.
    ## whitelist=(localhost|127\.0\.0\.1):(50030|50070|50060|50075)

    # Comma-separated list of regular expressions,
    # which match any prefix of 'host:port/path' of requested proxy target.
    # This does not support matching GET parameters.
    ## blacklist=


###########################################################################
# Settings to configure HBase Browser
###########################################################################

[hbase]
  # Comma-separated list of HBase Thrift servers for clusters in the format of '(name|host:port)'.
  # Use full hostname with security.
  # If using Kerberos we assume GSSAPI SASL, not PLAIN.
  hbase_clusters={{hbase_cluster}}

  # HBase configuration directory, where hbase-site.xml is located.
  hbase_conf_dir={{hbase_conf_dir}}

  # Hard limit of rows or columns per row fetched before truncating.
  truncate_limit = {{hbase_truncate_limit}}

  # 'buffered' is the default of the HBase Thrift Server and supports security.
  # 'framed' can be used to chunk up responses,
  # which is useful when used in conjunction with the nonblocking server in Thrift.
  thrift_transport={{hbase_thrift_transport}}

  # TODO Add ssl_cert_ca_verify
  # Choose whether Hue should validate certificates received from the server.
  ## ssl_cert_ca_verify=true


###########################################################################
# Settings to configure Solr Search
###########################################################################

[search]

  # URL of the Solr Server
  solr_url={{solr_url}}

  # Requires FQDN in solr_url if enabled
  {% if security_enabled %}
  security_enabled={{security_enabled}}
  {% else %}
  ## security_enabled=false
  {% endif %}

  ## Query sent when no term is entered
  empty_query={{solr_empty_query}}

  # TODO Del latest
  # Use latest Solr 5.2+ features.
  latest={{solr_latest}}

  # TODO Add download_limit
  ## Download limit with max of 15k
  ## download_limit=1000


###########################################################################
# Settings to configure Solr API lib
###########################################################################

[libsolr]

  # Choose whether Hue should validate certificates received from the server.
  ssl_cert_ca_verify={{solr_ssl_cert_ca_verify}}

  # Default path to Solr in ZooKeeper.
  solr_zk_path={{solr_zk_path}}


###########################################################################
# Settings to configure Solr Indexer
###########################################################################

[indexer]

  # TODO Del solrctl_path
  # Location of the solrctl binary.
  solrctl_path={{solr_solrctl_path}}

  # TODO Del enable_new_indexer
  # Flag to turn on the morphline based Solr indexer.
  enable_new_indexer={{solr_enable_new_indexer}}

  # TODO Add config_indexer_libs_path
  # Filesystem directory containing Solr Morphline indexing libs.
  ## config_indexer_libs_path=/tmp/smart_indexer_lib

  # TODO Add config_jdbc_libs_path
  # Filesystem directory containing JDBC libs.
  ## config_jdbc_libs_path=/user/oozie/libext/jdbc_drivers

  # TODO Add config_jars_libs_path
  # Filesystem directory containing jar libs.
  ## config_jars_libs_path=/user/oozie/libext/libs

  # TODO Add enable_scalable_indexer
  # Flag to turn on the Solr Morphline indexer.
  ## enable_scalable_indexer=true

  # TODO Add enable_sqoop
  # Flag to turn on Sqoop ingest.
  ## enable_sqoop=true

  # TODO Add enable_kafka
  # Flag to turn on Kafka topic ingest.
  ## enable_kafka=false

  # TODO Add enable_direct_upload
  # Flag to turn on the direct upload of a small file.
  ## enable_direct_upload=true


###########################################################################
# Settings to configure Job Designer
###########################################################################

[jobsub]

  # Location on local FS where examples and template are stored.
  local_data_dir={{jobsub_local_data_dir}}

  # Location on local FS where sample data is stored
  sample_data_dir={{jobsub_sample_data_dir}}


###########################################################################
# Settings to configure Job Browser.
###########################################################################

[jobbrowser]
  # Share submitted jobs information with all users. If set to false,
  # submitted jobs are visible only to the owner and administrators.
  share_jobs={{jobbrowser_share_jobs}}

  # Whether to disalbe the job kill button for all users in the jobbrowser
  disable_killing_jobs={{jobbrowser_disable_killing_jobs}}

  # Offset in bytes where a negative offset will fetch the last N bytes for the given log file (default 1MB).
  log_offset={{jobbrowser_log_offset}}

  # TODO Add max_job_fetch
  # Maximum number of jobs to fetch and display when pagination is not supported for the type.
  ## max_job_fetch=500

  # TODO Add enable_v2
  # Show the version 2 of app which unifies all the past browsers into one.
  ## enable_v2=true

  # TODO Add enable_query_browser
  # Show the Impala query section for listing and showing more troubleshooting information.
  ## enable_query_browser=true

  # TODO Add enable_hive_query_browser
  # Show the Hive section for listing the query history and providing more troubleshooting information.
  ## enable_hive_query_browser=false

  # TODO Add enable_queries_list
  # Show the Queries section for listing Hive/Impala query history and providing more troubleshooting information.
  ## enable_queries_list=false

  # TODO Add use_proxy
  # Use the proxy API instead of the ORM to access the query_store.
  ## use_proxy=true

  # TODO Add [[query_store]] module
  [[query_store]]
    # URL of Query Store API server.
    ##server_url=http://localhost:8080/


# TODO Add [security] module
###########################################################################
# Settings to configure Sentry / Security App.
###########################################################################

[security]

  # Use Sentry API V1 for Hive.
  ## hive_v1=true

  # Use Sentry API V2 for Hive.
  ## hive_v2=false

  # Use Sentry API V2 for Solr.
  ## solr_v2=true


###########################################################################
# Settings to configure the Zookeeper application.
###########################################################################

[zookeeper]

  [[clusters]]

    [[[default]]]
      # Zookeeper ensemble. Comma separated list of Host/Port.
      # e.g. localhost:2181,localhost:2182,localhost:2183
      host_ports={{zookeeper_host_port}}

      # The URL of the REST contrib service (required for znode browsing).
      rest_url={{zookeeper_rest_url}}

      # Name of Kerberos principal when using security.
      {% if security_enabled %}
      principal_name={{zk_principal}}
      {% else %}
      ## principal_name=zookeeper/_HOST@EXAMPLE.COM
      {% endif %} 


###########################################################################
# Settings for the User Admin application
###########################################################################

[useradmin]
  # Default home directory permissions
  home_dir_permissions=0750

  # TODO Add use_home_dir_permissions
  # Disable to use umask from hdfs else new user home directory would be created with the permissions from home_dir_permissions
  ## use_home_dir_permissions=true

  # The name of the default user group that users will be a member of
  default_user_group=default

  [[password_policy]]
    # Set password policy to all users. The default policy requires password to be at least 8 characters long,
    # and contain both uppercase and lowercase letters, numbers, and special characters.

    ## is_enabled=true
    ## pwd_regex="^(?=.*?[A-Z])(?=(.*[a-z]){1,})(?=(.*[\d]){1,})(?=(.*[\W_]){1,}).{8,}$"
    ## pwd_hint="The password must be at least 8 characters long, and must contain both uppercase and lowercase letters, at least one number, and at least one special character."
    ## pwd_error_message="The password must be at least 8 characters long, and must contain both uppercase and lowercase letters, at least one number, and at least one special character."


###########################################################################
# Settings to configure liboozie
###########################################################################

[liboozie]
  # The URL where the Oozie service runs on. This is required in order for
  # users to submit jobs. Empty value disables the config check.
  oozie_url={{oozie_url}}

  # Requires FQDN in oozie_url if enabled
  {% if security_enabled %}
  security_enabled={{security_enabled}}
  {% else %}
  ## security_enabled=false
  {% endif %}
  # Location on HDFS where the workflows/coordinator are deployed when submitted.
  remote_deployement_dir={{oozie_remote_deployement_dir}}

###########################################################################
# Settings for the AWS lib
###########################################################################

[aws]
  # TODO Add has_iam_detection
  # Enable the detection of an IAM role providing the credentials automatically. It can take a few seconds.
  ## has_iam_detection=false

  [[aws_accounts]]
    # Default AWS account
    ## [[[default]]]
      # AWS credentials
      ## access_key_id=
      ## secret_access_key=
      # TODO Add security_token
      ## security_token=

      # TODO Add access_key_id_script
      # Execute this script to produce the AWS access key ID.
      ## access_key_id_script=/path/access_key_id.sh

      # TODO Add secret_access_key_script
      # Execute this script to produce the AWS secret access key.
      ## secret_access_key_script=/path/secret_access_key.sh

      # Allow to use either environment variables or
      # EC2 InstanceProfile to retrieve AWS credentials.
      ## allow_environment_credentials=yes

      # AWS region to use
      ## region=us-east-1

      # TODO Add host
      # Endpoint overrides
      ## host=

      # TODO Add 
      # Endpoint overrides
      ## proxy_address=
      ## proxy_port=8080
      ## proxy_user=
      ## proxy_pass=

      # TODO Add is_secure
      # Secure connections are the default, but this can be explicitly overridden:
      ## is_secure=true

      # TODO Add calling_format
<!--      # The default calling format uses https://<bucket-name>.s3.amazonaws.com but-->
      # this may not make sense if DNS is not configured in this way for custom endpoints.
<!--      # e.g. Use boto.s3.connection.OrdinaryCallingFormat for https://s3.amazonaws.com/<bucket-name>-->
      ## calling_format=boto.s3.connection.OrdinaryCallingFormat

      # TODO Add key_expiry
      # The time in seconds before a delegate key is expired. Used when filebrowser/redirect_download is used. Default to 4 Hours.
      ## key_expiry=14400


# TODO Add [azure] module
###########################################################################
# Settings for the Azure lib
###########################################################################
[azure]
  [[azure_accounts]]
    # Default Azure account
    [[[default]]]
      # Azure credentials
      ## client_id=

      # Execute this script to produce the ADLS client id.
      ## client_id_script=/path/client_id.sh
      ## client_secret=

      # Execute this script to produce the ADLS client secret.
      ## client_secret_script=/path/client_secret.sh
      ## tenant_id=

      # Execute this script to produce the ADLS tenant id.
      ## tenant_id_script=/path/tenant_id.sh

  [[adls_clusters]]
    # Default ADLS cluster
    [[[default]]]
<!--      ## e.g. fs_defaultfs=adl://<account_name>.azuredatalakestore.net-->
      # fs_defaultfs=

<!--      ## e.g. webhdfs_url=https://<account_name>.azuredatalakestore.net/webhdfs/v1-->
      # webhdfs_url=

  [[abfs_clusters]]
     # Default ABFS cluster
     [[[default]]]
       ## enable_defaultfs_from_coresite=true

<!--       ## e.g. fs_defaultfs=abfs://<container_name>@<account_name>.dfs.core.windows.net-->
       # fs_defaultfs=

<!--       ## e.g. webhdfs_url=https://<account_name>.dfs.core.windows.net-->
       # webhdfs_url=


# TODO Add [libsentry] module
###########################################################################
# Settings for the Sentry lib
###########################################################################

[libsentry]
  # Hostname or IP of server.
  ## hostname=localhost

  # Port the sentry service is running on.
  ## port=8038

  # Sentry configuration directory, where sentry-site.xml is located.
  ## sentry_conf_dir=/etc/sentry/conf

  # Number of seconds when the privilege list of a user is cached.
  ## privilege_checker_caching=300


###########################################################################
# Settings to configure the ZooKeeper Lib
###########################################################################

[libzookeeper]
  # ZooKeeper ensemble. Comma separated list of Host/Port.
  # e.g. localhost:2181,localhost:2182,localhost:2183
  ensemble={{zookeeper_host_port}}

  # Name of Kerberos principal when using security.
  {% if security_enabled %}
  principal_name={{zk_principal}}
  {% else %}
  ## principal_name=zookeeper
  {% endif %}


###########################################################################
# Settings for the RDBMS application
###########################################################################

[librdbms]
  # The RDBMS app can have any number of databases configured in the databases
  # section. A database is known by its section name
  # (IE sqlite, mysql, psql, and oracle in the list below).

  [[databases]]
    # sqlite configuration.
    ## [[[sqlite]]]
      # Name to show in the UI.
      ## nice_name=SQLite

      # For SQLite, name defines the path to the database.
      ## name=/tmp/sqlite.db

      # Database backend to use.
      ## engine=sqlite

      # Database options to send to the server when connecting.
      # https://docs.djangoproject.com/en/1.4/ref/databases/
      ## options={}
   {% if rdbms_sqlite_engine %}
    [[[sqlite]]]
      # Name to show in the UI.
      nice_name={{rdbms_sqlite_nice_name}}

      # For SQLite, name defines the path to the database.
      name={{rdbms_sqlite_name}}
      # Database backend to use.
      engine=sqlite

      # Database options to send to the server when connecting.
      # https://docs.djangoproject.com/en/1.4/ref/databases/
      options={{rdbms_sqlite_options}}
   {% endif %}

    # mysql, oracle, or postgresql configuration.
   {% if rdbms_mysql_engine %}
    [[[mysql]]]
      # Name to show in the UI.
      nice_name={{rdbms_mysql_nice_name}}

      # For MySQL and PostgreSQL, name is the name of the database.
      # For Oracle, Name is instance of the Oracle server. For express edition
      # this is 'xe' by default.
      name={{rdbms_mysql_name}}

      # Database backend to use. This can be:
      # 1. mysql
      # 2. postgresql
      # 3. oracle
      engine=mysql

      # IP or hostname of the database to connect to.
      host={{rdbms_mysql_host}}

      # Port the database server is listening to. Defaults are:
      # 1. MySQL: 3306
      # 2. PostgreSQL: 5432
      # 3. Oracle Express Edition: 1521
      port={{rdbms_mysql_port}}

      # Username to authenticate with when connecting to the database.
      user={{rdbms_mysql_user}}

      # Password matching the username to authenticate with when
      # connecting to the database.
      password={{rdbms_mysql_password}}

      # Database options to send to the server when connecting.
      # https://docs.djangoproject.com/en/1.4/ref/databases/
      options={{rdbms_mysql_options}}

   {% endif %}
   {% if rdbms_postgresql_engine %}
    [[[postgresql]]]
      # Name to show in the UI.
      nice_name={{rdbms_postgresql_nice_name}}

      # For MySQL and PostgreSQL, name is the name of the database.
      # For Oracle, Name is instance of the Oracle server. For express edition
      # this is 'xe' by default.
      name={{rdbms_postgresql_name}}

      # Database backend to use. This can be:
      # 1. mysql
      # 2. postgresql
      # 3. oracle
      engine=postgresql

      # IP or hostname of the database to connect to.
      host={{rdbms_postgresql_host}}

      # Port the database server is listening to. Defaults are:
      # 1. MySQL: 3306
      # 2. PostgreSQL: 5432
      # 3. Oracle Express Edition: 1521
      port={{rdbms_postgresql_port}}

      # Username to authenticate with when connecting to the database.
      user={{rdbms_postgresql_user}}

      # Password matching the username to authenticate with when
      # connecting to the database.
      password={{rdbms_postgresql_password}}

      # Database options to send to the server when connecting.
      # https://docs.djangoproject.com/en/1.4/ref/databases/
      options={{rdbms_postgresql_options}}

      # TODO Add schema
      # Database schema, to be used only when public schema is revoked in postgres
      schema=public
   {% endif %}
   {% if rdbms_oracle_engine %}
    [[[oracle]]]
      # Name to show in the UI.
      nice_name={{rdbms_oracle_nice_name}}

      # For MySQL and PostgreSQL, name is the name of the database.
      # For Oracle, Name is instance of the Oracle server. For express edition
      # this is 'xe' by default.
      name={{rdbms_oracle_name}}

      # Database backend to use. This can be:
      # 1. mysql
      # 2. postgresql
      # 3. oracle
      engine=oracle

      # IP or hostname of the database to connect to.
      host={{rdbms_oracle_host}}

      # Port the database server is listening to. Defaults are:
      # 1. MySQL: 3306
      # 2. PostgreSQL: 5432
      # 3. Oracle Express Edition: 1521
      port={{rdbms_oracle_port}}

      # Username to authenticate with when connecting to the database.
      user={{rdbms_oracle_user}}

      # Password matching the username to authenticate with when
      # connecting to the database.
      password={{rdbms_oracle_password}}

      # Database options to send to the server when connecting.
      # https://docs.djangoproject.com/en/1.4/ref/databases/
      options={{rdbms_oracle_options}}
   {% endif %}
###########################################################################
# Settings to configure SAML
###########################################################################

[libsaml]
  # Xmlsec1 binary path. This program should be executable by the user running Hue.
  ## xmlsec_binary=/usr/local/bin/xmlsec1

  # Entity ID for Hue acting as service provider.
  # Can also accept a pattern where '(base_url)' will be replaced with server URL base.
  ## entity_id="(base_url)/saml2/metadata/"

  # Create users from SSO on login.
  ## create_users_on_login=true

  # Required attributes to ask for from IdP.
  # This requires a comma separated list.
  ## required_attributes=uid

  # Optional attributes to ask for from IdP.
  # This requires a comma separated list.
  ## optional_attributes=

  # IdP metadata in the form of a file. This is generally an XML file containing metadata that the Identity Provider generates.
  ## metadata_file=

  # Private key to encrypt metadata with.
  ## key_file=

  # Signed certificate to send along with encrypted metadata.
  ## cert_file=

  # TODO Add accepted_time_diff
  # If your computer and another computer that you are communicating with are not in synch regarding the computer clock, then here you can state how big a difference you are prepared to accept in milliseconds.
  ## accepted_time_diff=0

  # Path to a file containing the password private key.
  ## key_file_password=/path/key

  # Execute this script to produce the private key password. This will be used when 'key_file_password' is not set.
  ## key_file_password_script=/path/pwd.sh

  # A mapping from attributes in the response from the IdP to django user attributes.
  ## user_attribute_mapping={'uid': ('username', )}

  # Have Hue initiated authn requests be signed and provide a certificate.
  ## authn_requests_signed=false

  # TODO Add want_response_signed
  # Have Hue initiated authn response be signed.
  ## want_response_signed=false

  # TODO Add want_assertions_signed
  # Have Hue initiated authn assertions response be signed.
  ## want_assertions_signed=false

  # Have Hue initiated logout requests be signed and provide a certificate.
  ## logout_requests_signed=false

  # Username can be sourced from 'attributes' or 'nameid'.
  ## username_source=attributes

  # Performs the logout or not.
  ## logout_enabled=true

  # TODO Add required_groups
  # Comma separated list of group names which are all required to complete the authentication. e.g. admin,sales.
  ## required_groups=

  # TODO Add required_groups_attribute
  # Name of the SAML attribute containing the list of groups the user belongs to.
  ## required_groups_attribute=groups

# TODO Del [libopenid] module
###########################################################################
# Settings to configure OpenID
###########################################################################

[libopenid]
  # (Required) OpenId SSO endpoint url.
  ## server_endpoint_url=https://www.google.com/accounts/o8/id

  # OpenId 1.1 identity url prefix to be used instead of SSO endpoint url
  # This is only supported if you are using an OpenId 1.1 endpoint
  ## identity_url_prefix=https://app.onelogin.com/openid/your_company.com/

  # Create users from OPENID on login.
  ## create_users_on_login=true

  # Use email for username
  ## use_email_for_username=true


###########################################################################
# Settings to configure OAuth
###########################################################################

[liboauth]
  # NOTE:
  # To work, each of the active (i.e. uncommented) service must have
  # applications created on the social network.
  # Then the "consumer key" and "consumer secret" must be provided here.
  #
  # The addresses where to do so are:
  # Twitter:  https://dev.twitter.com/apps
  # Google+ : https://cloud.google.com/
  # Facebook: https://developers.facebook.com/apps
  # Linkedin: https://www.linkedin.com/secure/developer
  #
  # Additionnaly, the following must be set in the application settings:
  # Twitter:  Callback URL (aka Redirect URL) must be set to http://YOUR_HUE_IP_OR_DOMAIN_NAME/oauth/social_login/oauth_authenticated
  # Google+ : CONSENT SCREEN must have email address
  # Facebook: Sandbox Mode must be DISABLED
  # Linkedin: "In OAuth User Agreement", r_emailaddress is REQUIRED

  # The Consumer key of the application
  ## consumer_key_twitter=
  ## consumer_key_google=
  ## consumer_key_facebook=
  ## consumer_key_linkedin=

  # The Consumer secret of the application
  ## consumer_secret_twitter=
  ## consumer_secret_google=
  ## consumer_secret_facebook=
  ## consumer_secret_linkedin=

  # The Request token URL
  ## request_token_url_twitter=https://api.twitter.com/oauth/request_token
  ## request_token_url_google=https://accounts.google.com/o/oauth2/auth
  ## request_token_url_linkedin=https://www.linkedin.com/uas/oauth2/authorization
  ## request_token_url_facebook=https://graph.facebook.com/oauth/authorize

  # The Access token URL
  ## access_token_url_twitter=https://api.twitter.com/oauth/access_token
  ## access_token_url_google=https://accounts.google.com/o/oauth2/token
  ## access_token_url_facebook=https://graph.facebook.com/oauth/access_token
  ## access_token_url_linkedin=https://api.linkedin.com/uas/oauth2/accessToken

  # The Authenticate URL
  ## authenticate_url_twitter=https://api.twitter.com/oauth/authorize
  ## authenticate_url_google=https://www.googleapis.com/oauth2/v1/userinfo?access_token=
  ## authenticate_url_facebook=https://graph.facebook.com/me?access_token=
  ## authenticate_url_linkedin=https://api.linkedin.com/v1/people/~:

  # Username Map. Json Hash format.
  # Replaces username parts in order to simplify usernames obtained
  # Example: {"@sub1.domain.com":"_S1", "@sub2.domain.com":"_S2"}
  # converts 'email@sub1.domain.com' to 'email_S1'
  ## username_map={}

  # Whitelisted domains (only applies to Google OAuth). CSV format.
  ## whitelisted_domains_google=


# TODO Add [kafka] module
###########################################################################
# Settings to configure Kafka
###########################################################################

[kafka]

  [[kafka]]
    # Enable the Kafka integration.
    ## is_enabled=false

    # URL of Kafka REST API.
    ## api_url=http://localhost:8082

    # URL of Kafka Ksql API.
    ## ksql_api_url=http://localhost:8088

    # URL of Schema Registry API.
    ## schema_registry_api_url=http://localhost:8081


###########################################################################
# Settings to configure Metadata
###########################################################################

[metadata]
  # For metadata tagging and enhancement features

  # TODO Add [[manager]] module
  [[manager]]
    # Cloudera Manager API URL (without version suffix).
    ## api_url=http://localhost:7180/api

  # TODO Modify [[optimizer]] module
  [[optimizer]]
    # TODO Add ============================  START  =============================
    # Mode of optimization: off, local, api.
    ## mode=off

    # Type of Optimizer connector to use, e.g. optimizer, navopt, dummy.
    ## interface=navopt

    # Hostname of Optimizer API service.
    ## hostname=navoptapi.us-west-1.optimizer.altus.cloudera.com

    # The name of the key of the service.
    ## auth_key_id=e0819f3a-1e6f-4904-be69-5b704bacd1245

    # The private part of the key associated with the auth_key.
    ## auth_key_secret='-----BEGIN PRIVATE KEY....'

    # Execute this script to produce the auth_key secret. This will be used when `auth_key_secret` is not set.
    ## auth_key_secret_script=/path/to/script.sh

    # The name of the workload where queries are uploaded and optimizations are calculated from. Automatically guessed from auth_key and cluster_id if not specified.
    ## tenant_id=

    # Perform Sentry privilege filtering.
    # Default to true automatically if the cluster is secure.
    ## apply_sentry_permissions=False

    # Cache timeout in milliseconds for the Optimizer metadata used in assist, autocomplete, etc.
    # Defaults to 10 days, set to 0 to disable caching.
    ## cacheable_ttl=864000000

    # Automatically upload queries after their execution in order to improve recommendations.
    ## auto_upload_queries=true

    # Automatically upload queried tables DDL in order to improve recommendations.
    ## auto_upload_ddl=true

    # Automatically upload queried tables and columns stats in order to improve recommendations.
    ## auto_upload_stats=false

    # Allow admins to upload the last N executed queries in the quick start wizard. Use 0 to disable.
    ## query_history_upload_limit=10000
    # TODO Add ============================  END  =============================

    # TODO Del ============================  START  =============================
    # For SQL query and table analysis
    # Base URL to Optimizer API.
    ## api_url=https://alpha.optimizer.cloudera.com
    # The name of the product or group which will have API access to the emails associated with it.
    ## product_name=hue
    # A secret passphrase associated with the productName
    ## product_secret=hue
    # Execute this script to produce the product secret. This will be used when 'product_secret' is not set.
    ## product_secret_script=

    # The email of the Optimizer account you want to associate with the Product.
    ## email=hue@gethue.com
    # The password associated with the Optimizer account you to associate with the Product.
    ## email_password=hue
    # Execute this script to produce the email password. This will be used when 'email_password' is not set.
    ## password_script=

    # In secure mode (HTTPS), if Optimizer SSL certificates have to be verified against certificate authority.
    ## ssl_cert_ca_verify=True
    # TODO Del ============================  END  =============================

  # TODO Add [[catalog]] module
  [[catalog]]
    # The type of Catalog: Apache Atlas, Cloudera Navigator...
    ## interface=atlas

    # Catalog API URL (without version suffix).
    ## api_url=http://localhost:21000/atlas/v2

    # Username of the CM user used for authentication.
    ## server_user=hue

    # Password of the user used for authentication.
    ## server_password=

    # Limits found entities to a specific cluster. When empty the entities from all clusters will be included in the
    # search results.
    ## search_cluster=

    # Set to true when authenticating via kerberos instead of username/password
    ## kerberos_enabled=core_site.is_kerberos_enabled()

    # Directory of the configurations.
    ## conf_dir=HUE_CONF_DIR/hive-conf

  # Deprecated by [[catalog]]
  [[navigator]]
    # For tagging tables, files and getting lineage of data.
    # Navigator API URL with version (without version suffix)
    ## api_url=http://localhost:7187/api

    # TODO Del auth_username, auth_password
    # Navigator API HTTP authentication username and password
    # Override the desktop default username and password of the hue user used for authentications with other services.
    # e.g. Used for LDAP/PAM pass-through authentication.
    ## auth_username=hue
    ## auth_password=

    # TODO Add ============================  START  =============================
    # Which authentication to use: CM or external via LDAP or SAML.
    ## navmetadataserver_auth_type=CMDB

    # Username of the CM user used for authentication.
    ## navmetadataserver_cmdb_user=hue

    # CM password of the user used for authentication.
    ## navmetadataserver_cmdb_password=

    # Execute this script to produce the CM password. This will be used when the plain password is not set.
    # navmetadataserver_cmdb_password_script=

    # Username of the LDAP user used for authentication.
    ## navmetadataserver_ldap_user=hue

    # LDAP password of the user used for authentication.
    ## navmetadataserver_ldap_ppassword=

    # Execute this script to produce the LDAP password. This will be used when the plain password is not set.
    ## navmetadataserver_ldap_password_script=

    # Username of the SAML user used for authentication.
    ## navmetadataserver_saml_user=hue

    ## SAML password of the user used for authentication.
    # navmetadataserver_saml_password=

    # Execute this script to produce the SAML password. This will be used when the plain password  is not set.
    ## navmetadataserver_saml_password_script=

    # Perform Sentry privilege filtering.
    # Default to true automatically if the cluster is secure.
    ## apply_sentry_permissions=False

    # Max number of items to fetch in one call in object search.
    ## fetch_size_search=450

    # Max number of items to fetch in one call in object search autocomplete.
    ## fetch_size_search_interactive=450

    # If metadata search is enabled, also show the search box in the left assist.
    ## enable_file_search=false
    # TODO Add ============================  END  =============================

  # TODO Add [[prometheus]] module
  [[prometheus]]
    # Configuration options for Prometheus API.
    ## api_url=http://localhost:9090/api
  </value>
  <value-attributes>
    <type>content</type>
    <show-property-name>false</show-property-name>
  </value-attributes>
  <on-ambari-upgrade add="true"/>
  </property>  
</configuration>
